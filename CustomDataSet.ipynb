{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp39-none-macosx_10_9_x86_64.whl (135.3 MB)\n",
      "Requirement already satisfied: typing-extensions in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.1-cp39-cp39-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "Requirement already satisfied: requests in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: torch==1.13.1 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/macbookpro/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.14.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images in folders to select 1000 images, using all images in folders.\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, drawn_folder, normal_folder, transform=None):\n",
    "        self.drawn_images = [os.path.join(drawn_folder, f) for f in os.listdir(drawn_folder) if f.endswith('.png')]\n",
    "        self.normal_images = [os.path.join(normal_folder, f) for f in os.listdir(normal_folder) if f.endswith('.png')]\n",
    "        self.transform = transform\n",
    "        try:\n",
    "            self.drawn_images = random.sample(self.drawn_images, 1000)\n",
    "            self.normal_images = random.sample(self.normal_images, 1000)\n",
    "        except ValueError:\n",
    "            print(\"Not enough images in folders to select 1000 images, using all images in folders.\")\n",
    "            self.drawn_images = self.drawn_images[::5]\n",
    "            self.normal_images = self.normal_images[::5]\n",
    "    def __len__(self):\n",
    "        return len(self.drawn_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        drawn_img = Image.open(self.drawn_images[idx*5])\n",
    "        normal_img = Image.open(self.normal_images[idx*5])\n",
    "\n",
    "        # Normaliser les images\n",
    "        drawn_img = drawn_img.resize((256, 256))\n",
    "        normal_img = normal_img.resize((256, 256))\n",
    "\n",
    "        # Appliquer les transformations\n",
    "        if self.transform:\n",
    "            drawn_img = self.transform(drawn_img)\n",
    "            normal_img = self.transform(normal_img)\n",
    "\n",
    "        return {'drawn_img': drawn_img, 'normal_img': normal_img}\n",
    "\n",
    "# Utiliser le dataset\n",
    "drawn_folder = '/Users/macbookpro/Downloads/all-in-one/sketch-rendered/width-3'\n",
    "normal_folder = '/Users/macbookpro/Downloads/all-in-one/sketch'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = CustomDataset(drawn_folder, normal_folder, transform)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e17245beed66d97676295f18f5af02f52c1ff0b20014505018e20bb50c7c46d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
